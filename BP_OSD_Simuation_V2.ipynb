{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run qsu.ipynb\n",
    "import numpy as np\n",
    "import sympy\n",
    "import networkx as nx\n",
    "from qecsim import paulitools as pt \n",
    "from qecsim.models.generic import DepolarizingErrorModel\n",
    "from qecsim.models.toric import ToricCode\n",
    "import nbimporter\n",
    "import galois\n",
    "from matplotlib import cbook\n",
    "from matplotlib import cm\n",
    "from matplotlib.colors import LightSource\n",
    "import matplotlib.animation as animation\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Tuple\n",
    "import hypergraph_prod_code as hpc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def belief_prop(H: np.array, s: np.array, p: float, max_iter: int) -> Tuple:\n",
    "    \"\"\" \n",
    "    Belief Propagation Algorithm for Decoding LDPC Codes\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    H - parity-check matrix corresponding to either X or Z checks\n",
    "    s - Error syndrome\n",
    "    p - Channel error rate for chosen noise channel\n",
    "    max_iter - Maximum number of iterations to run BP algorithm for\n",
    "    \"\"\"\n",
    "    data_to_parity = np.zeros((len(H[0]),len(H)), dtype=float)\n",
    "    parity_to_data = np.zeros((len(H), len(H[0])), dtype=float)\n",
    "    H_tanner_graph = hpc.parity_check_mat_to_tanner(H)\n",
    "    \n",
    "    # Channel Log Likelihood Ratio\n",
    "    p_l = np.log((1 - p)/p)\n",
    "    \n",
    "    P_1 = np.zeros((len(H[0]),), dtype=float)\n",
    "    e_BP = np.zeros((len(H[0]),), dtype=float)\n",
    "\n",
    "    # (1) Initialization\n",
    "    for edge in H_tanner_graph.edges:\n",
    "        data_node_num = int(edge[0][1:])\n",
    "        parity_node_num = int(edge[1][1:])\n",
    "        data_to_parity[data_node_num][parity_node_num] = p_l \n",
    "\n",
    "    for iter in range(1, max_iter + 1):\n",
    "        # Scaling Factor\n",
    "        a = 1 - 2**(-1 * iter)\n",
    "\n",
    "        # (2) Parity to Data Messages\n",
    "        for edge in H_tanner_graph.edges:\n",
    "            parity_node_num = int(edge[1][1:])\n",
    "            data_node_num = int(edge[0][1:])\n",
    "\n",
    "            # Get list of neighbors of current parity_node set minus the current data node\n",
    "            V = list(nx.neighbors(H_tanner_graph, edge[1]))\n",
    "            V.remove(edge[0])\n",
    "\n",
    "            # Get messages from elements of V to current parity node\n",
    "            data_to_par_msgs = [data_to_parity[int(v[1:])][parity_node_num] for v in V]\n",
    "            w = np.min([np.abs(msg) for msg in data_to_par_msgs])\n",
    "            parity_to_data[parity_node_num][data_node_num] = ((-1) ** int(s[parity_node_num])) * a * np.prod(np.sign(data_to_par_msgs)) * w \n",
    "\n",
    "        # (3) Data to Parity Messages\n",
    "        for edge in H_tanner_graph.edges:\n",
    "            data_node_num = int(edge[0][1:])\n",
    "            parity_node_num = int(edge[1][1:])\n",
    "\n",
    "            # Get list of neighbors of current data node set minus the current parity node\n",
    "            U = list(nx.neighbors(H_tanner_graph, edge[0]))\n",
    "            U.remove(edge[1])\n",
    "\n",
    "            # Get messages from elements of U to current data node\n",
    "            par_to_data_msgs = [parity_to_data[int(u[1:])][data_node_num] for u in U]\n",
    "            data_to_parity[data_node_num][parity_node_num] = p_l + np.sum(par_to_data_msgs)\n",
    "\n",
    "        # Hard Decision\n",
    "        for edge in H_tanner_graph.edges:\n",
    "            data_node_num = int(edge[0][1:])\n",
    "            parity_node_num = int(edge[1][1:])\n",
    "\n",
    "            # Get list of neighbors of current data node\n",
    "            U = list(nx.neighbors(H_tanner_graph, edge[0]))\n",
    "\n",
    "            par_to_data_msgs = [parity_to_data[int(u[1:])][data_node_num] for u in U]\n",
    "            P_1[data_node_num] = p_l + np.sum(par_to_data_msgs)\n",
    "            e_BP[data_node_num] = -1 * np.sign(P_1[data_node_num])\n",
    "        \n",
    "        # (4) Termination Check\n",
    "        e_BP = e_BP * (e_BP > 0)\n",
    "        #print(e_BP)\n",
    "        if (np.array_equal(np.dot(H, e_BP), s)):\n",
    "            return True, e_BP, P_1 \n",
    "\n",
    "    return False, e_BP, P_1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checks for Errors:\n",
    "* Method of casting via GF\n",
    "* Permutation of columns of $H$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OSD_0(H: np.array, P_1: np.array, s: np.array) -> np.array:\n",
    "    \"\"\" \n",
    "    The Ordered Statistics Decoding (OSD) Zero algorithm is a post-processing \n",
    "    algorithm utilized when BP fails to converge \n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    H - parity check matrix\n",
    "    P_1 - BP soft decision vector\n",
    "    s - Error syndrome \n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    Error string\n",
    "    \"\"\"\n",
    "    GF = galois.GF(2)\n",
    "\n",
    "    # Get rank of parity check matrix \n",
    "    H_rank = np.linalg.matrix_rank(GF(H))\n",
    "    \n",
    "    # Sort soft decision vector \n",
    "    P_1_sorted_pos = np.argsort(P_1, kind='stable')\n",
    "    P_1_sorted = [P_1[i] for i in P_1_sorted_pos]\n",
    "\n",
    "    # Remove remove row from 'H' and related position from 's'\n",
    "    del_pos = np.random.choice(len(H))\n",
    "    H_d = np.delete(H, del_pos, axis=0)\n",
    "    s_d = GF(np.delete(s, del_pos, axis=0))\n",
    "\n",
    "    # Rearrange columns of H to match the reordered soft-decision vector\n",
    "    H_d[:] = H_d[:, P_1_sorted_pos]\n",
    "\n",
    "    # Select first RANK(H) linearly independent columns of above rearrangement\n",
    "    H_rref, inds = sympy.Matrix(H_d).rref()\n",
    "    H_rref = np.array(H_rref)\n",
    "    H_S = GF(np.vstack(([H_d[:, inds[i]] for i in range(0, H_rank)])).T)\n",
    "    #H_S_inv = GF(np.mod((np.linalg.inv(H_S)).astype('int32'),2))\n",
    "    H_S_inv = np.linalg.inv(H_S)\n",
    "    \n",
    "    # Calculate the OSD-0 solution on the basis-bits\n",
    "    e_S = H_S_inv @ s_d\n",
    "    e_ST = np.hstack((e_S, GF(np.zeros((len(H[0]) - H_rank,), dtype='int32'))))\n",
    "    \n",
    "    \n",
    "    # Map the OSD-0 solution to the original bit-ordering\n",
    "    e_OSD = GF(np.zeros((len(H[0]),), dtype='int32'))\n",
    "    for i in range(len(P_1_sorted_pos)):\n",
    "        e_OSD[P_1_sorted_pos[i]] = e_ST[i]\n",
    "    \n",
    "    return e_OSD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mod(x,modulus):\n",
    "    numer, denom = x.as_numer_denom()\n",
    "    return numer*sympy.mod_inverse(denom,modulus) % modulus    \n",
    "\n",
    "# Turn to Ordered Statistics Decoding if BP fails to converge\n",
    "def OSD_0_V1(H: np.array, P_1: np.array, s: np.array) -> np.array:\n",
    "    \"\"\" \n",
    "    The Ordered Statistics Decoding (OSD) Zero algorithm is a post-processing \n",
    "    algorithm utilized when BP fails to converge \n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    H - parity check matrix\n",
    "    P_1 - BP soft decision vector\n",
    "    s - Error syndrome \n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    Error string\n",
    "    \"\"\"\n",
    "    GF = galois.GF(2)\n",
    "    # Get the rank of the parity check matrix\n",
    "    H_rank = np.linalg.matrix_rank(GF(H))\n",
    "    print(H_rank)\n",
    "\n",
    "    # Maintain a mapping between bit positions and elements of the BP soft-decision vector\n",
    "    P_1_sorted_pos = np.argsort(P_1, kind='stable')[::-1]\n",
    "    P_1_sorted = [P_1[i] for i in P_1_sorted_pos]\n",
    "    print(P_1_sorted_pos)\n",
    "    print(P_1_sorted)\n",
    "\n",
    "    # Rearrange columns of H to match the reordered soft-decision vector\n",
    "    H[:] = H[:, P_1_sorted_pos]\n",
    "\n",
    "    # Randomly remove a row from 'H' and related position from syndrome\n",
    "    del_pos = np.random.choice(len(H))\n",
    "    print(del_pos)\n",
    "    print(H,s)\n",
    "    H_del = np.delete(H, del_pos, axis=0)\n",
    "    s_del = np.delete(s, del_pos)\n",
    "\n",
    "    # Select first RANK(H) linearly independent columns of above rearrangement\n",
    "    H_rref, inds = sympy.Matrix(H_del).rref()\n",
    "\n",
    "    H_rref = H_rref.applyfunc(lambda x : mod(x,2))\n",
    "    H_rref, inds = sympy.Matrix(H_rref).rref()\n",
    "    H_S = np.vstack(([H_del[:, inds[i]] for i in range(0, H_rank)]))\n",
    "    print(H_S)\n",
    "    H_S_inv = np.mod(np.linalg.inv(H_S), 2)\n",
    "    print(H_S_inv)\n",
    "    \n",
    "\n",
    "    # Calculate the OSD-0 solution on the basis-bits\n",
    "    e_S = np.linalg.inv(H_S) @ s_del\n",
    "    e_ST = np.hstack((e_S, np.zeros((len(H[0]) - H_rank,))))\n",
    "\n",
    "    # Map the OSD-0 solution to the original bit-ordering\n",
    "    e_OSD = np.zeros((len(H[0]),))\n",
    "    for i in range(len(P_1_sorted_pos)):\n",
    "        e_OSD[P_1_sorted_pos[i]] = e_ST[i]\n",
    "\n",
    "    return e_OSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_H_J(H:np.array, J: List, s_p: np.array):\n",
    "    if (J == []):\n",
    "        H_J = []\n",
    "        H_J_s = np.array(s_p.T)\n",
    "    else:\n",
    "        H_J = np.vstack([H[:, i] for i in J])\n",
    "        H_J_s = np.vstack((H_J,s_p)).T\n",
    "    return H_J, H_J_s\n",
    "\n",
    "def replace_pos(e_p: np.array, x: np.array, J: List):\n",
    "    count = 0\n",
    "    for i in range(len(e_p)):\n",
    "        if(i in J):\n",
    "            e_p[i] = x[count]\n",
    "            count += 1\n",
    "\n",
    "    return e_p\n",
    "\n",
    "\n",
    "# Turn to Ordered Statistics Decoding if BP fails to converge\n",
    "def OSD_0_V2(H: np.array, s: np.array, P_1: np.array, e_p: np.array, num_qubits: int) -> np.array:\n",
    "    \"\"\" \n",
    "    The Ordered Statistics Decoding (OSD) Zero algorithm is a post-processing \n",
    "    algorithm utilized when BP fails to converge \n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    H - Parity check matrix\n",
    "    s - Error syndrome \n",
    "    P_1 - Soft decision vector\n",
    "    e_p - Hard decision vector\n",
    "    num_qubits - Number of qubits\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    Error string e such that He = s\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    # Maintain a mapping between bit positions and elements of the BP soft-decision vector\n",
    "    P_1_sorted_pos = np.argsort(P_1, kind='stable')[::-1]\n",
    "    P_1_sorted = [P_1[i] for i in P_1_sorted_pos]\n",
    "\n",
    "    # Rearrange columns of H to match the reordered soft-decision vector\n",
    "    H[:] = H[:, P_1_sorted_pos]\n",
    "    \"\"\"\n",
    "\n",
    "    # Want to construct information set J\n",
    "    J = []\n",
    "    s_p = np.mod(s + (H @ e_p),2)\n",
    "    for i in range(num_qubits):\n",
    "        H_J, H_J_s = get_H_J(H, J, s_p)\n",
    "        if (np.linalg.matrix_rank(H_J_s) == np.linalg.matrix_rank(H_J)):\n",
    "            break \n",
    "        J_p = J + [i]\n",
    "        H_J_p, _ = get_H_J(H, J_p, s_p)\n",
    "        if (np.linalg.matrix_rank(H_J_p) > np.linalg.matrix_rank(H_J)):\n",
    "            J = J_p\n",
    "            s_p += e_p[i] * H[:,i]\n",
    "    rref, _ = sympy.Matrix.rref(sympy.Matrix(H_J_s))\n",
    "    x = rref[:,-1]\n",
    "    e = replace_pos(e_p, x, s_p)\n",
    "    return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OSD_0_V3(H: np.array, s: np.array, P_1: np.array, e_p: np.array, num_qubits: int) -> np.array:\n",
    "    \"\"\" \n",
    "    The Ordered Statistics Decoding (OSD) Zero algorithm is a post-processing \n",
    "    algorithm utilized when BP fails to converge \n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    H - Parity check matrix\n",
    "    s - Error syndrome \n",
    "    P_1 - Soft decision vector\n",
    "    e_p - Hard decision vector\n",
    "    num_qubits - Number of qubits\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    Error string e such that He = s\n",
    "    \"\"\"\n",
    "    # Maintain a mapping between bit positions and elements of the BP soft-decision vector\n",
    "    P_1_sorted_pos = np.argsort(P_1, kind='stable')[::-1]\n",
    "    P_1_sorted = [P_1[i] for i in P_1_sorted_pos]\n",
    "\n",
    "    # Rearrange columns of H to match the reordered soft-decision vector\n",
    "    H[:] = H[:, P_1_sorted_pos]\n",
    "\n",
    "    # Solve for He=s\n",
    "    s = np.reshape(s, (len(s),1))\n",
    "    aug_mat = sympy.Matrix(np.concatenate((H,s), axis=1), domain=sympy.ZZ(2))\n",
    "    aug_mat, inds = sympy.Matrix.rref(aug_mat)\n",
    "    print(np.array(aug_mat))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop to see probability distribution evolution across many runs of BP decoder\n",
    "def prob_likelihood_evol(dim: int):\n",
    "    # Array of likelihoods (soft-decision vectors) for each run\n",
    "    BP_like_Z = []\n",
    "    BP_like_X = []\n",
    "\n",
    "    # Define code\n",
    "    my_code = ToricCode(dim, dim);\n",
    "    my_error_model = DepolarizingErrorModel()\n",
    "    \n",
    "    # Define error probability and randomly select seed for errors\n",
    "    error_probability = 0.1 \n",
    "    rn = np.random.randint(1,100000)\n",
    "    rng = np.random.default_rng(rn)\n",
    "\n",
    "    # Get random error\n",
    "    error = my_error_model.generate(my_code, error_probability, rng)\n",
    "\n",
    "    # Get syndrome of error\n",
    "    syndrome = pt.bsp(error, my_code.stabilizers.T)\n",
    "\n",
    "    # Get X and Z parity check matrices and related error vectors \n",
    "    Z_stabs = (my_code.stabilizers[:dim ** 2])[:, 2 * dim ** 2:]\n",
    "    X_stabs = (my_code.stabilizers[dim ** 2:])[:, :2 * dim ** 2]\n",
    "    Z_error = error[2 * dim**2:]\n",
    "    X_error = error[:2 * dim**2]\n",
    "    Z_syndrome = np.mod(X_stabs @ Z_error,2)\n",
    "    X_syndrome = np.mod(Z_stabs @ X_error, 2)\n",
    "\n",
    "    for num_iter in range(1, 2 * dim ** 2 + 1):\n",
    "        converged_Z, e_BP_Z, P_1_Z = belief_prop(X_stabs, Z_syndrome, error_probability, num_iter)\n",
    "        converged_X, e_BP_X, P_1_X = belief_prop(Z_stabs, X_syndrome, error_probability, num_iter)\n",
    "        \n",
    "        BP_like_Z.append(P_1_Z)\n",
    "        BP_like_Z.append(P_1_X)\n",
    "\n",
    "    BP_like_Z = np.array(BP_like_Z)\n",
    "    BP_like_X = np.array(BP_like_X)\n",
    "    return (BP_like_Z, BP_like_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samyaknn/anaconda3/envs/qc_env/lib/python3.9/site-packages/matplotlib/animation.py:887: UserWarning: Animation was deleted without rendering anything. This is most likely not intended. To prevent deletion, assign the Animation to a variable, e.g. `anim`, that exists until you have outputted the Animation using `plt.show()` or `anim.save()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dim = 3\n",
    "SD_Z, SD_X = prob_likelihood_evol(dim)\n",
    "x = np.linspace(0, 4 * dim ** 2 - 1, 4 * dim ** 2, dtype=int)\n",
    "y = np.linspace(0, 2 * dim ** 2 - 1, 2 * dim ** 2, dtype=int)\n",
    "\n",
    "fig = plt.figure(figsize=(12,8))\n",
    "ax = plt.subplot(111, frameon=False)\n",
    "\n",
    "def update(*args):\n",
    "    # Shift all data to the right\n",
    "    SD_Z[:, 1:] = SD_Z[:, :-1]\n",
    "\n",
    "    # Fill-in new values\n",
    "    SD_Z[:, 0] = np.random.uniform(0, 1, len(data))\n",
    "\n",
    "    # Update data\n",
    "    for i in range(len(data)):\n",
    "        lines[i].set_ydata(i + G * data[i])\n",
    "\n",
    "    # Return modified artists\n",
    "    return lines\n",
    "\n",
    "anim = animation.FuncAnimation(fig, update, interval=10)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize models\n",
    "dim = 3\n",
    "my_code = ToricCode(dim,dim)\n",
    "my_error_model = DepolarizingErrorModel()\n",
    "GF = galois.GF(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      "error:\n",
      "┼─·─┼─X─┼─·\n",
      "X   ·   X  \n",
      "┼─·─┼─·─┼─·\n",
      "·   ·   ·  \n",
      "┼─·─┼─·─┼─·\n",
      "·   Z   ·  \n"
     ]
    }
   ],
   "source": [
    "# Set physical error probability to 10%\n",
    "error_probability = 0.1\n",
    "# Seed random number generator for repeatability\n",
    "#rng = np.random.default_rng(15355)\n",
    "rng = np.random.default_rng()\n",
    "\n",
    "# Error: random error based on error probability\n",
    "error = my_error_model.generate(my_code, error_probability, rng)\n",
    "print(error)\n",
    "print(('error:\\n{}'.format(my_code.new_pauli(error))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0]\n",
      "syndrome:\n",
      "┼───X───┼──\n",
      "│ Z │   │  \n",
      "┼───┼───┼──\n",
      "│   │   │  \n",
      "┼───X───┼──\n",
      "│   │ Z │  \n"
     ]
    }
   ],
   "source": [
    "# Syndrome: Stabilizers that do not commute with the error\n",
    "syndrome = pt.bsp(error, my_code.stabilizers.T)\n",
    "print(syndrome)\n",
    "print(('syndrome:\\n{}'.format(my_code.ascii_art(syndrome))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z_error: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      "X_error: [0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "Z_stabs = (my_code.stabilizers[:dim ** 2])[:, 2 * dim ** 2:]\n",
    "X_stabs = (my_code.stabilizers[dim ** 2:])[:, :2 * dim ** 2]\n",
    "#print(str(Z_stabs) + \"\\n\" + str(X_stabs))\n",
    "#print(np.mod(X_stabs @ Z_stabs.T,2))\n",
    "Z_error = error[2 * dim**2:]\n",
    "X_error = error[:2 * dim**2]\n",
    "print(\"Z_error: \" + str(Z_error))\n",
    "print(\"X_error: \" + str(X_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z_syndrome: [0 0 0 0 1 0 0 1 0]\n",
      "X_syndrome: [1 0 0 0 0 0 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "Z_syndrome = np.mod(X_stabs @ Z_error,2)\n",
    "print(\"Z_syndrome: \" + str(Z_syndrome))\n",
    "X_syndrome = np.mod(Z_stabs @ X_error, 2)\n",
    "print(\"X_syndrome: \" + str(X_syndrome))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "converged_Z, e_BP_Z, P_1_Z = belief_prop(X_stabs, Z_syndrome, 0.1, 2 * dim ** 2)\n",
    "converged_X, e_BP_X, P_1_X = belief_prop(Z_stabs, X_syndrome, 0.1, 2 * dim ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True [-0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0.  1. -0.] [ 3.84514301  3.84514301  3.84514301  5.49306144  5.49306144  7.14097988\n",
      "  3.84514301  3.84514301  3.84514301  5.49306144  2.19722458  5.49306144\n",
      "  5.49306144  2.19722458  5.49306144  3.84514301 -2.74653072  3.84514301]\n",
      "\n",
      "\n",
      "False [-0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0.] [0.13227582 0.13227582 3.08871213 2.19722458 3.08871213 5.15366089\n",
      " 3.08871213 2.19722458 5.15366089 2.19722458 0.13227582 3.08871213\n",
      " 5.15366089 3.08871213 5.15366089 3.08871213 0.13227582 2.19722458]\n"
     ]
    }
   ],
   "source": [
    "print(converged_Z, e_BP_Z, P_1_Z)\n",
    "print('\\n')\n",
    "print(converged_X, e_BP_X, P_1_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BP ON X FAILED\n",
      "[0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "if (converged_X == True and converged_Z == True):\n",
    "    e_OSD_Z = e_BP_Z\n",
    "    e_OSD_X = e_BP_X\n",
    "if (converged_Z == False):\n",
    "    print(\"BP ON Z FAILED\")\n",
    "    #e_OSD_Z = np.mod(OSD_0_V2(X_stabs, Z_syndrome, P_1_Z, e_BP_Z, 2 * dim ** 2), 2)\n",
    "    #e_OSD_Z = np.mod(OSD_0_V3(X_stabs, Z_syndrome, P_1_Z, e_BP_Z, 2 * dim ** 2), 2)\n",
    "    e_OSD_Z = np.array(OSD_0(X_stabs, P_1_Z, Z_syndrome))\n",
    "    if (converged_X == True):\n",
    "        e_OSD_X = e_BP_X\n",
    "    print(e_OSD_Z)\n",
    "if (converged_X == False):\n",
    "    print(\"BP ON X FAILED\")\n",
    "    #e_OSD_X = np.mod(OSD_0_V2(Z_stabs, X_syndrome, P_1_X, e_BP_X, 2 * dim ** 2), 2)\n",
    "    #e_OSD_X = np.mod(OSD_0_V3(Z_stabs, X_syndrome, P_1_X, e_BP_X, 2 * dim ** 2), 2)\n",
    "    e_OSD_X = np.array(OSD_0(Z_stabs, P_1_X, X_syndrome))\n",
    "    if (converged_Z == True):\n",
    "        e_OSD_Z = e_BP_Z\n",
    "    print(e_OSD_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 1. 0. 0. 1. 0.]\n",
      "[1 0 0 0 0 0 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "# Check consistency with syndromes measured.\n",
    "print(np.mod(X_stabs @ e_OSD_Z, 2))\n",
    "print(np.mod(Z_stabs @ e_OSD_X, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: [0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      "Recovery operation: [0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      "Commutation with stabilizers: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Commutation with logicals: [0 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "print(\"Error: \" + str(error))\n",
    "recovery = np.array((np.hstack((e_OSD_X, e_OSD_Z))), dtype='int32')\n",
    "print(\"Recovery operation: \" + str(recovery))\n",
    "\n",
    "# check recovery ^ error commutes with stabilizers\n",
    "print(\"Commutation with stabilizers: \" + str(pt.bsp(recovery ^ error, my_code.stabilizers.T)))\n",
    "\n",
    "# success iff recovery ^ error commutes with logicals\n",
    "print(\"Commutation with logicals: \" + str(pt.bsp(recovery ^ error, my_code.logicals.T)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qc_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5a2db16169323f9c61c6ed4d885397ad0494f2e790734ab97aaeab1bbd202ff7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
