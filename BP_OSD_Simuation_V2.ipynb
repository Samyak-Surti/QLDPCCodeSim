{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run qsu.ipynb\n",
    "import numpy as np\n",
    "import sympy\n",
    "import networkx as nx\n",
    "from qecsim import paulitools as pt \n",
    "from qecsim.models.generic import DepolarizingErrorModel\n",
    "from qecsim.models.toric import ToricCode\n",
    "from tqdm import tqdm\n",
    "import nbimporter\n",
    "import galois\n",
    "from matplotlib import cbook\n",
    "from matplotlib import cm\n",
    "from matplotlib.colors import LightSource\n",
    "import matplotlib.animation as animation\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Tuple\n",
    "import hypergraph_prod_code as hpc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def belief_prop(H: np.array, s: np.array, p: float, max_iter: int) -> Tuple:\n",
    "    \"\"\" \n",
    "    Belief Propagation Algorithm for Decoding LDPC Codes\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    H - parity-check matrix corresponding to either X or Z checks\n",
    "    s - Error syndrome\n",
    "    p - Channel error rate for chosen noise channel\n",
    "    max_iter - Maximum number of iterations to run BP algorithm for\n",
    "    \"\"\"\n",
    "    data_to_parity = np.zeros((len(H[0]),len(H)), dtype=float)\n",
    "    parity_to_data = np.zeros((len(H), len(H[0])), dtype=float)\n",
    "    H_tanner_graph = hpc.parity_check_mat_to_tanner(H)\n",
    "    \n",
    "    # Channel Log Likelihood Ratio\n",
    "    p_l = np.log((1 - p)/p)\n",
    "    \n",
    "    P_1 = np.zeros((len(H[0]),), dtype=float)\n",
    "    e_BP = np.zeros((len(H[0]),), dtype=float)\n",
    "\n",
    "    # (1) Initialization\n",
    "    for edge in H_tanner_graph.edges:\n",
    "        data_node_num = int(edge[0][1:])\n",
    "        parity_node_num = int(edge[1][1:])\n",
    "        data_to_parity[data_node_num][parity_node_num] = p_l \n",
    "\n",
    "    for iter in range(1, max_iter + 1):\n",
    "        # Scaling Factor\n",
    "        a = 1 - 2**(-1 * iter)\n",
    "\n",
    "        # (2) Parity to Data Messages\n",
    "        for edge in H_tanner_graph.edges:\n",
    "            parity_node_num = int(edge[1][1:])\n",
    "            data_node_num = int(edge[0][1:])\n",
    "\n",
    "            # Get list of neighbors of current parity_node set minus the current data node\n",
    "            V = list(nx.neighbors(H_tanner_graph, edge[1]))\n",
    "            V.remove(edge[0])\n",
    "\n",
    "            # Get messages from elements of V to current parity node\n",
    "            data_to_par_msgs = [data_to_parity[int(v[1:])][parity_node_num] for v in V]\n",
    "            w = np.min([np.abs(msg) for msg in data_to_par_msgs])\n",
    "            parity_to_data[parity_node_num][data_node_num] = ((-1) ** int(s[parity_node_num])) * a * np.prod(np.sign(data_to_par_msgs)) * w \n",
    "\n",
    "        # (3) Data to Parity Messages\n",
    "        for edge in H_tanner_graph.edges:\n",
    "            data_node_num = int(edge[0][1:])\n",
    "            parity_node_num = int(edge[1][1:])\n",
    "\n",
    "            # Get list of neighbors of current data node set minus the current parity node\n",
    "            U = list(nx.neighbors(H_tanner_graph, edge[0]))\n",
    "            U.remove(edge[1])\n",
    "\n",
    "            # Get messages from elements of U to current data node\n",
    "            par_to_data_msgs = [parity_to_data[int(u[1:])][data_node_num] for u in U]\n",
    "            data_to_parity[data_node_num][parity_node_num] = p_l + np.sum(par_to_data_msgs)\n",
    "\n",
    "        # Hard Decision\n",
    "        for edge in H_tanner_graph.edges:\n",
    "            data_node_num = int(edge[0][1:])\n",
    "            parity_node_num = int(edge[1][1:])\n",
    "\n",
    "            # Get list of neighbors of current data node\n",
    "            U = list(nx.neighbors(H_tanner_graph, edge[0]))\n",
    "\n",
    "            par_to_data_msgs = [parity_to_data[int(u[1:])][data_node_num] for u in U]\n",
    "            P_1[data_node_num] = p_l + np.sum(par_to_data_msgs)\n",
    "            e_BP[data_node_num] = -1 * np.sign(P_1[data_node_num])\n",
    "        \n",
    "        # (4) Termination Check\n",
    "        e_BP = e_BP * (e_BP > 0)\n",
    "        #print(e_BP)\n",
    "        if (np.array_equal(np.dot(H, e_BP), s)):\n",
    "            return True, e_BP, P_1 \n",
    "\n",
    "    return False, e_BP, P_1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checks for Errors:\n",
    "* Method of casting via GF\n",
    "* Permutation of columns of $H$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OSD_0(H: np.array, P_1: np.array, s: np.array) -> np.array:\n",
    "    \"\"\" \n",
    "    The Ordered Statistics Decoding (OSD) Zero algorithm is a post-processing \n",
    "    algorithm utilized when BP fails to converge \n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    H - parity check matrix\n",
    "    P_1 - BP soft decision vector\n",
    "    s - Error syndrome \n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    Error string\n",
    "    \"\"\"\n",
    "    GF = galois.GF(2)\n",
    "\n",
    "    # Get rank of parity check matrix \n",
    "    H_rank = np.linalg.matrix_rank(GF(H))\n",
    "    \n",
    "    # Sort soft decision vector \n",
    "    P_1_sorted_pos = np.argsort(P_1, kind='stable')\n",
    "    P_1_sorted = [P_1[i] for i in P_1_sorted_pos]\n",
    "\n",
    "    # Remove remove row from 'H' and related position from 's'\n",
    "    del_pos = np.random.choice(len(H))\n",
    "    H_d = np.delete(H, del_pos, axis=0)\n",
    "    s_d = GF(np.delete(s, del_pos, axis=0))\n",
    "\n",
    "    # Rearrange columns of H to match the reordered soft-decision vector\n",
    "    H_d[:] = H_d[:, P_1_sorted_pos]\n",
    "\n",
    "    # Select first RANK(H) linearly independent columns of above rearrangement\n",
    "    H_rref, inds = sympy.Matrix(H_d).rref()\n",
    "    H_rref = np.array(H_rref)\n",
    "    H_S = GF(np.vstack(([H_d[:, inds[i]] for i in range(0, H_rank)])).T)\n",
    "    #H_S_inv = GF(np.mod((np.linalg.inv(H_S)).astype('int32'),2))\n",
    "    H_S_inv = np.linalg.inv(H_S)\n",
    "    \n",
    "    # Calculate the OSD-0 solution on the basis-bits\n",
    "    e_S = H_S_inv @ s_d\n",
    "    e_ST = np.hstack((e_S, GF(np.zeros((len(H[0]) - H_rank,), dtype='int32'))))\n",
    "    \n",
    "    \n",
    "    # Map the OSD-0 solution to the original bit-ordering\n",
    "    e_OSD = GF(np.zeros((len(H[0]),), dtype='int32'))\n",
    "    for i in range(len(P_1_sorted_pos)):\n",
    "        e_OSD[P_1_sorted_pos[i]] = e_ST[i]\n",
    "    \n",
    "    return e_OSD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mod(x,modulus):\n",
    "    numer, denom = x.as_numer_denom()\n",
    "    return numer*sympy.mod_inverse(denom,modulus) % modulus    \n",
    "\n",
    "# Turn to Ordered Statistics Decoding if BP fails to converge\n",
    "def OSD_0_V1(H: np.array, P_1: np.array, s: np.array) -> np.array:\n",
    "    \"\"\" \n",
    "    The Ordered Statistics Decoding (OSD) Zero algorithm is a post-processing \n",
    "    algorithm utilized when BP fails to converge \n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    H - parity check matrix\n",
    "    P_1 - BP soft decision vector\n",
    "    s - Error syndrome \n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    Error string\n",
    "    \"\"\"\n",
    "    GF = galois.GF(2)\n",
    "    # Get the rank of the parity check matrix\n",
    "    H_rank = np.linalg.matrix_rank(GF(H))\n",
    "    print(H_rank)\n",
    "\n",
    "    # Maintain a mapping between bit positions and elements of the BP soft-decision vector\n",
    "    P_1_sorted_pos = np.argsort(P_1, kind='stable')[::-1]\n",
    "    P_1_sorted = [P_1[i] for i in P_1_sorted_pos]\n",
    "    print(P_1_sorted_pos)\n",
    "    print(P_1_sorted)\n",
    "\n",
    "    # Rearrange columns of H to match the reordered soft-decision vector\n",
    "    H[:] = H[:, P_1_sorted_pos]\n",
    "\n",
    "    # Randomly remove a row from 'H' and related position from syndrome\n",
    "    del_pos = np.random.choice(len(H))\n",
    "    print(del_pos)\n",
    "    print(H,s)\n",
    "    H_del = np.delete(H, del_pos, axis=0)\n",
    "    s_del = np.delete(s, del_pos)\n",
    "\n",
    "    # Select first RANK(H) linearly independent columns of above rearrangement\n",
    "    H_rref, inds = sympy.Matrix(H_del).rref()\n",
    "\n",
    "    H_rref = H_rref.applyfunc(lambda x : mod(x,2))\n",
    "    H_rref, inds = sympy.Matrix(H_rref).rref()\n",
    "    H_S = np.vstack(([H_del[:, inds[i]] for i in range(0, H_rank)]))\n",
    "    print(H_S)\n",
    "    H_S_inv = np.mod(np.linalg.inv(H_S), 2)\n",
    "    print(H_S_inv)\n",
    "    \n",
    "\n",
    "    # Calculate the OSD-0 solution on the basis-bits\n",
    "    e_S = np.linalg.inv(H_S) @ s_del\n",
    "    e_ST = np.hstack((e_S, np.zeros((len(H[0]) - H_rank,))))\n",
    "\n",
    "    # Map the OSD-0 solution to the original bit-ordering\n",
    "    e_OSD = np.zeros((len(H[0]),))\n",
    "    for i in range(len(P_1_sorted_pos)):\n",
    "        e_OSD[P_1_sorted_pos[i]] = e_ST[i]\n",
    "\n",
    "    return e_OSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_H_J(H:np.array, J: List, s_p: np.array):\n",
    "    if (J == []):\n",
    "        H_J = []\n",
    "        H_J_s = np.array(s_p.T)\n",
    "    else:\n",
    "        H_J = np.vstack([H[:, i] for i in J])\n",
    "        H_J_s = np.vstack((H_J,s_p)).T\n",
    "    return H_J, H_J_s\n",
    "\n",
    "def replace_pos(e_p: np.array, x: np.array, J: List):\n",
    "    count = 0\n",
    "    for i in range(len(e_p)):\n",
    "        if(i in J):\n",
    "            e_p[i] = x[count]\n",
    "            count += 1\n",
    "\n",
    "    return e_p\n",
    "\n",
    "\n",
    "# Turn to Ordered Statistics Decoding if BP fails to converge\n",
    "def OSD_0_V2(H: np.array, s: np.array, P_1: np.array, e_p: np.array, num_qubits: int) -> np.array:\n",
    "    \"\"\" \n",
    "    The Ordered Statistics Decoding (OSD) Zero algorithm is a post-processing \n",
    "    algorithm utilized when BP fails to converge \n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    H - Parity check matrix\n",
    "    s - Error syndrome \n",
    "    P_1 - Soft decision vector\n",
    "    e_p - Hard decision vector\n",
    "    num_qubits - Number of qubits\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    Error string e such that He = s\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    # Maintain a mapping between bit positions and elements of the BP soft-decision vector\n",
    "    P_1_sorted_pos = np.argsort(P_1, kind='stable')[::-1]\n",
    "    P_1_sorted = [P_1[i] for i in P_1_sorted_pos]\n",
    "\n",
    "    # Rearrange columns of H to match the reordered soft-decision vector\n",
    "    H[:] = H[:, P_1_sorted_pos]\n",
    "    \"\"\"\n",
    "\n",
    "    # Want to construct information set J\n",
    "    J = []\n",
    "    s_p = np.mod(s + (H @ e_p),2)\n",
    "    for i in range(num_qubits):\n",
    "        H_J, H_J_s = get_H_J(H, J, s_p)\n",
    "        if (np.linalg.matrix_rank(H_J_s) == np.linalg.matrix_rank(H_J)):\n",
    "            break \n",
    "        J_p = J + [i]\n",
    "        H_J_p, _ = get_H_J(H, J_p, s_p)\n",
    "        if (np.linalg.matrix_rank(H_J_p) > np.linalg.matrix_rank(H_J)):\n",
    "            J = J_p\n",
    "            s_p += e_p[i] * H[:,i]\n",
    "    rref, _ = sympy.Matrix.rref(sympy.Matrix(H_J_s))\n",
    "    x = rref[:,-1]\n",
    "    e = replace_pos(e_p, x, s_p)\n",
    "    return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OSD_0_V3(H: np.array, s: np.array, P_1: np.array, e_p: np.array, num_qubits: int) -> np.array:\n",
    "    \"\"\" \n",
    "    The Ordered Statistics Decoding (OSD) Zero algorithm is a post-processing \n",
    "    algorithm utilized when BP fails to converge \n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    H - Parity check matrix\n",
    "    s - Error syndrome \n",
    "    P_1 - Soft decision vector\n",
    "    e_p - Hard decision vector\n",
    "    num_qubits - Number of qubits\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    Error string e such that He = s\n",
    "    \"\"\"\n",
    "    # Maintain a mapping between bit positions and elements of the BP soft-decision vector\n",
    "    P_1_sorted_pos = np.argsort(P_1, kind='stable')[::-1]\n",
    "    P_1_sorted = [P_1[i] for i in P_1_sorted_pos]\n",
    "\n",
    "    # Rearrange columns of H to match the reordered soft-decision vector\n",
    "    H[:] = H[:, P_1_sorted_pos]\n",
    "\n",
    "    # Solve for He=s\n",
    "    s = np.reshape(s, (len(s),1))\n",
    "    aug_mat = sympy.Matrix(np.concatenate((H,s), axis=1), domain=sympy.ZZ(2))\n",
    "    aug_mat, inds = sympy.Matrix.rref(aug_mat)\n",
    "    print(np.array(aug_mat))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop to see probability distribution evolution across many runs of BP decoder\n",
    "def prob_likelihood_evol(dim: int):\n",
    "    # Array of likelihoods (soft-decision vectors) for each run\n",
    "    BP_like_Z = []\n",
    "    BP_like_X = []\n",
    "\n",
    "    # Define code\n",
    "    my_code = ToricCode(dim, dim);\n",
    "    my_error_model = DepolarizingErrorModel()\n",
    "    \n",
    "    # Define error probability and randomly select seed for errors\n",
    "    error_probability = 0.1 \n",
    "    rn = np.random.randint(1,100000)\n",
    "    rng = np.random.default_rng(rn)\n",
    "\n",
    "    # Get random error\n",
    "    error = my_error_model.generate(my_code, error_probability, rng)\n",
    "\n",
    "    # Get syndrome of error\n",
    "    syndrome = pt.bsp(error, my_code.stabilizers.T)\n",
    "\n",
    "    # Get X and Z parity check matrices and related error vectors \n",
    "    Z_stabs = (my_code.stabilizers[:dim ** 2])[:, 2 * dim ** 2:]\n",
    "    X_stabs = (my_code.stabilizers[dim ** 2:])[:, :2 * dim ** 2]\n",
    "    Z_error = error[2 * dim**2:]\n",
    "    X_error = error[:2 * dim**2]\n",
    "    Z_syndrome = np.mod(X_stabs @ Z_error,2)\n",
    "    X_syndrome = np.mod(Z_stabs @ X_error, 2)\n",
    "\n",
    "    for num_iter in range(1, 2 * dim ** 2 + 1):\n",
    "        converged_Z, e_BP_Z, P_1_Z = belief_prop(X_stabs, Z_syndrome, error_probability, num_iter)\n",
    "        converged_X, e_BP_X, P_1_X = belief_prop(Z_stabs, X_syndrome, error_probability, num_iter)\n",
    "        \n",
    "        BP_like_Z.append(P_1_Z)\n",
    "        BP_like_Z.append(P_1_X)\n",
    "\n",
    "    BP_like_Z = np.array(BP_like_Z)\n",
    "    BP_like_X = np.array(BP_like_X)\n",
    "    return (BP_like_Z, BP_like_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dim = 3\n",
    "SD_Z, SD_X = prob_likelihood_evol(dim)\n",
    "x = np.linspace(0, 4 * dim ** 2 - 1, 4 * dim ** 2, dtype=int)\n",
    "y = np.linspace(0, 2 * dim ** 2 - 1, 2 * dim ** 2, dtype=int)\n",
    "\n",
    "fig = plt.figure(figsize=(12,8))\n",
    "ax = plt.subplot(111, frameon=False)\n",
    "\n",
    "def update(*args):\n",
    "    # Shift all data to the right\n",
    "    SD_Z[:, 1:] = SD_Z[:, :-1]\n",
    "\n",
    "    # Fill-in new values\n",
    "    SD_Z[:, 0] = np.random.uniform(0, 1, len(data))\n",
    "\n",
    "    # Update data\n",
    "    for i in range(len(data)):\n",
    "        lines[i].set_ydata(i + G * data[i])\n",
    "\n",
    "    # Return modified artists\n",
    "    return lines\n",
    "\n",
    "anim = animation.FuncAnimation(fig, update, interval=10)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize models\n",
    "dim = 3\n",
    "my_code = ToricCode(dim,dim)\n",
    "my_error_model = DepolarizingErrorModel()\n",
    "GF = galois.GF(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
      "error:\n",
      "┼─·─┼─·─┼─·\n",
      "·   ·   ·  \n",
      "┼─Y─┼─·─┼─·\n",
      "Y   ·   ·  \n",
      "┼─·─┼─·─┼─·\n",
      "·   ·   ·  \n"
     ]
    }
   ],
   "source": [
    "# Set physical error probability to 10%\n",
    "error_probability = 0.1\n",
    "# Seed random number generator for repeatability\n",
    "#rng = np.random.default_rng(15355)\n",
    "rng = np.random.default_rng()\n",
    "\n",
    "# Error: random error based on error probability\n",
    "error = my_error_model.generate(my_code, error_probability, rng)\n",
    "print(error)\n",
    "print(('error:\\n{}'.format(my_code.new_pauli(error))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0]\n",
      "syndrome:\n",
      "┼───┼───┼──\n",
      "│ Z │   │  \n",
      "┼───X───┼──\n",
      "│   │   │ Z\n",
      "X───┼───┼──\n",
      "│   │   │  \n"
     ]
    }
   ],
   "source": [
    "# Syndrome: Stabilizers that do not commute with the error\n",
    "syndrome = pt.bsp(error, my_code.stabilizers.T)\n",
    "print(syndrome)\n",
    "print(('syndrome:\\n{}'.format(my_code.ascii_art(syndrome))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z_error: [0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
      "X_error: [0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "Z_stabs = (my_code.stabilizers[:dim ** 2])[:, 2 * dim ** 2:]\n",
    "X_stabs = (my_code.stabilizers[dim ** 2:])[:, :2 * dim ** 2]\n",
    "#print(str(Z_stabs) + \"\\n\" + str(X_stabs))\n",
    "#print(np.mod(X_stabs @ Z_stabs.T,2))\n",
    "Z_error = error[2 * dim**2:]\n",
    "X_error = error[:2 * dim**2]\n",
    "print(\"Z_error: \" + str(Z_error))\n",
    "print(\"X_error: \" + str(X_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z_syndrome: [0 1 0 1 0 0 0 0 0]\n",
      "X_syndrome: [1 0 0 0 0 1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "Z_syndrome = np.mod(X_stabs @ Z_error,2)\n",
    "print(\"Z_syndrome: \" + str(Z_syndrome))\n",
    "X_syndrome = np.mod(Z_stabs @ X_error, 2)\n",
    "print(\"X_syndrome: \" + str(X_syndrome))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "converged_Z, e_BP_Z, P_1_Z = belief_prop(X_stabs, Z_syndrome, 0.1, 2 * dim ** 2)\n",
    "converged_X, e_BP_X, P_1_X = belief_prop(Z_stabs, X_syndrome, 0.1, 2 * dim ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False [-0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0.] [3.08871213 5.15366089 5.15366089 0.13227582 2.19722458 3.08871213\n",
      " 0.13227582 3.08871213 2.19722458 3.08871213 2.19722458 5.15366089\n",
      " 0.13227582 0.13227582 3.08871213 2.19722458 3.08871213 5.15366089]\n",
      "\n",
      "\n",
      "False [-0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0.] [2.19722458 5.15366089 3.08871213 0.13227582 3.08871213 0.13227582\n",
      " 3.08871213 5.15366089 2.19722458 0.13227582 2.19722458 3.08871213\n",
      " 0.13227582 3.08871213 2.19722458 3.08871213 5.15366089 5.15366089]\n"
     ]
    }
   ],
   "source": [
    "print(converged_Z, e_BP_Z, P_1_Z)\n",
    "print('\\n')\n",
    "print(converged_X, e_BP_X, P_1_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BP ON Z FAILED\n",
      "8\n",
      "[0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
      "BP ON X FAILED\n",
      "8\n",
      "[0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "if (converged_X == True and converged_Z == True):\n",
    "    e_OSD_Z = e_BP_Z\n",
    "    e_OSD_X = e_BP_X\n",
    "if (converged_Z == False):\n",
    "    print(\"BP ON Z FAILED\")\n",
    "    #e_OSD_Z = np.mod(OSD_0_V2(X_stabs, Z_syndrome, P_1_Z, e_BP_Z, 2 * dim ** 2), 2)\n",
    "    #e_OSD_Z = np.mod(OSD_0_V3(X_stabs, Z_syndrome, P_1_Z, e_BP_Z, 2 * dim ** 2), 2)\n",
    "    e_OSD_Z = np.array(OSD_0(X_stabs, P_1_Z, Z_syndrome))\n",
    "    if (converged_X == True):\n",
    "        e_OSD_X = e_BP_X\n",
    "    print(e_OSD_Z)\n",
    "if (converged_X == False):\n",
    "    print(\"BP ON X FAILED\")\n",
    "    #e_OSD_X = np.mod(OSD_0_V2(Z_stabs, X_syndrome, P_1_X, e_BP_X, 2 * dim ** 2), 2)\n",
    "    #e_OSD_X = np.mod(OSD_0_V3(Z_stabs, X_syndrome, P_1_X, e_BP_X, 2 * dim ** 2), 2)\n",
    "    e_OSD_X = np.array(OSD_0(Z_stabs, P_1_X, X_syndrome))\n",
    "    if (converged_Z == True):\n",
    "        e_OSD_Z = e_BP_Z\n",
    "    print(e_OSD_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 1 0 0 0 0 0]\n",
      "[1 0 0 0 0 1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Check consistency with syndromes measured.\n",
    "print(np.mod(X_stabs @ e_OSD_Z, 2))\n",
    "print(np.mod(Z_stabs @ e_OSD_X, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: [0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
      "Recovery operation: [0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
      "Commutation with stabilizers: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Commutation with logicals: [0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(\"Error: \" + str(error))\n",
    "recovery = np.array((np.hstack((e_OSD_X, e_OSD_Z))), dtype='int32')\n",
    "print(\"Recovery operation: \" + str(recovery))\n",
    "\n",
    "# check recovery ^ error commutes with stabilizers\n",
    "print(\"Commutation with stabilizers: \" + str(pt.bsp(recovery ^ error, my_code.stabilizers.T)))\n",
    "\n",
    "# success iff recovery ^ error commutes with logicals\n",
    "print(\"Commutation with logicals: \" + str(pt.bsp(recovery ^ error, my_code.logicals.T)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"get the syndrome of the pauli operator \"\"\"\n",
    "\n",
    "def twisted_product(stab_binary, pauli_binary):\n",
    "    \"\"\"\n",
    "    take twisted product of stabilizer with pauli to calculate commutator \n",
    "    \"\"\"\n",
    "    \n",
    "    if len(stab_binary.shape) == 1:\n",
    "        # if we have only 1 stabilizer\n",
    "        L = int(len(stab_binary)/2)\n",
    "        return (stab_binary[:L]@pauli_binary[L:] + stab_binary[L:]@pauli_binary[:L]) % 2\n",
    "    else:\n",
    "        # if we have a parity check \n",
    "        L = int(stab_binary.shape[1]/2)\n",
    "        assert stab_binary.shape[1] == len(pauli_binary)\n",
    "        syndrome = []\n",
    "        for i in range(stab_binary.shape[0]):\n",
    "            syndrome.append((stab_binary[i, :L]@pauli_binary[L:] + stab_binary[i, L:]@pauli_binary[:L]) % 2)\n",
    "        return np.array(syndrome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 4/100 [00:00<00:03, 28.46it/s]\n"
     ]
    },
    {
     "ename": "LinAlgError",
     "evalue": "Argument `A` is singular and not invertible because it does not have full rank of 8, but rank of 7.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/5d/012l939x26zc05mjshslzh2h0000gn/T/ipykernel_9153/133803012.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0me_OSD_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me_BP_X\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mconverged_Z\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0me_OSD_Z\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mOSD_0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_stabs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mP_1_Z\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mZ_syndrome\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mconverged_X\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0me_OSD_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me_BP_X\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/5d/012l939x26zc05mjshslzh2h0000gn/T/ipykernel_9153/1260877587.py\u001b[0m in \u001b[0;36mOSD_0\u001b[0;34m(H, P_1, s)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mH_S\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mH_d\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH_rank\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;31m#H_S_inv = GF(np.mod((np.linalg.inv(H_S)).astype('int32'),2))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0mH_S_inv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mH_S\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;31m# Calculate the OSD-0 solution on the basis-bits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36minv\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/topo_quant/lib/python3.9/site-packages/galois/_fields/_main.py\u001b[0m in \u001b[0;36m__array_function__\u001b[0;34m(self, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m   2663\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2664\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mfunc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_OVERRIDDEN_LINALG_FUNCTIONS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2665\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_OVERRIDDEN_LINALG_FUNCTIONS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2667\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mfunc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_UNSUPPORTED_FUNCTIONS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/topo_quant/lib/python3.9/site-packages/galois/_fields/_linalg.py\u001b[0m in \u001b[0;36minv\u001b[0;34m(A)\u001b[0m\n\u001b[1;32m    253\u001b[0m     \u001b[0mrank\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAI_rre\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mrank\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinAlgError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Argument `A` is singular and not invertible because it does not have full rank of {n}, but rank of {rank}.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0mA_inv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAI_rre\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLinAlgError\u001b[0m: Argument `A` is singular and not invertible because it does not have full rank of 8, but rank of 7."
     ]
    }
   ],
   "source": [
    "dim = 3\n",
    "my_code = ToricCode(dim,dim)\n",
    "my_error_model = DepolarizingErrorModel()\n",
    "GF = galois.GF(2)\n",
    "\n",
    "num_rounds = 100\n",
    "codespace_projection = [0]*num_rounds\n",
    "logical_errors = [0]*num_rounds\n",
    "uncorrected_logical_error_rate = [0]*num_rounds\n",
    "error_probability = 0.08\n",
    "count = 0\n",
    "\n",
    "for r in tqdm(range(num_rounds)):\n",
    "    rng = np.random.default_rng()\n",
    "    # Error: random error based on error probability\n",
    "    error = my_error_model.generate(my_code, error_probability, rng)\n",
    "    while (sum(error) == 0):\n",
    "        error = my_error_model.generate(my_code, error_probability, rng)\n",
    "\n",
    "    syndrome = pt.bsp(error, my_code.stabilizers.T)\n",
    "    Z_stabs = (my_code.stabilizers[:dim ** 2])[:, 2 * dim ** 2:]\n",
    "    X_stabs = (my_code.stabilizers[dim ** 2:])[:, :2 * dim ** 2]\n",
    "    Z_error = error[2 * dim**2:]\n",
    "    X_error = error[:2 * dim**2]\n",
    "    Z_syndrome = np.mod(X_stabs @ Z_error,2)\n",
    "    X_syndrome = np.mod(Z_stabs @ X_error, 2)\n",
    "    converged_Z, e_BP_Z, P_1_Z = belief_prop(X_stabs, Z_syndrome, 0.1, 2 * dim ** 2)\n",
    "    converged_X, e_BP_X, P_1_X = belief_prop(Z_stabs, X_syndrome, 0.1, 2 * dim ** 2)\n",
    "    if (converged_X == True and converged_Z == True):\n",
    "        e_OSD_Z = e_BP_Z\n",
    "        e_OSD_X = e_BP_X\n",
    "    if (converged_Z == False):\n",
    "        e_OSD_Z = np.array(OSD_0(X_stabs, P_1_Z, Z_syndrome))\n",
    "        if (converged_X == True):\n",
    "            e_OSD_X = e_BP_X\n",
    "    if (converged_X == False):\n",
    "        e_OSD_X = np.array(OSD_0(Z_stabs, P_1_X, X_syndrome))\n",
    "        if (converged_Z == True):\n",
    "            e_OSD_Z = e_BP_Z\n",
    "\n",
    "    recovery = np.array((np.hstack((e_OSD_X, e_OSD_Z))), dtype='int32')\n",
    "\n",
    "    if sum(pt.bsp(recovery ^ error, my_code.stabilizers.T)) > 0:\n",
    "        codespace_projection[r] = 1\n",
    "    if sum(pt.bsp(recovery ^ error, my_code.logicals.T)) > 0:\n",
    "        logical_errors[r] = 1\n",
    "    if sum(pt.bsp(error, my_code.logicals.T)) > 0:\n",
    "        uncorrected_logical_error_rate[r] = 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('topo_quant')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4046caf55f50b54fa7ffdea1ad98452a8feb9cf62ccba5e4c76fe622e38f8fa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
